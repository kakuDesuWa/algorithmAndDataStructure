# Overview

## Basic Concepts:

- 数据: 描述客观事物属性的数, 字符等的集合)

- 数据元素: 数据的基本单位, 通常做整体考虑, 一个数据元素可由若干数据项组成, 数据项是构成数据元素的不可分割的最小单位. 如一个学生(数据元素), 由学号, 姓名, 性别等数据项组成. 

- 数据对象: 是具有相同性质的数据元素的集合, 如(int)

- 数据类型:**** 
    1. 原子类型(int, float, string)
    2. 结构类型(structure, array, map)
    3. 抽象数据类型(ADT)

- 数据结构:
    1. 逻辑结构(线性与非线性, eg: 集合, 线性结构, 树形结构, 图状结构或网状结构)
    2. 存储结构(顺序存储, 链式存储, 索引存储, 散列存储)
    3. 数据运算(插入, 删除, 寻找等)

- 算法: 
    1. 特点: 有穷性, 确定性, 可行性, 输入, 输出
    2. "好"的标准: 正确性, 可读性, 健壮性, 效率与低存储量需求

- 算法效率的度量
    1. 时间复杂度:  
    在算法中被重复执行的次数. 算法中所有语句的频度之和记为T(n), 它是该算法问题规模n的函数, 时间复杂度主要分析T(n)的数量级. 算法中基本运算(最深层循环内的语句)的频度与T(n)同数量级, 因此通常采用算法中基本运算的频度f(n)来分析算法的时间复杂度, 记为: T(n) = O(f(n)).   
    同时, 算法的时间复杂度不仅依赖于问题的规模, 也取决于待输入数据的性质(如输入数据元素的初始状态)  
    常见的渐近时间复杂度(logn: 指以2为底):  
    2. 空间复杂度:  
    它是问题规模n的函数, 渐近空间复杂度简称为空间复杂度, 记为: S(n) = O(g(n))
    
    > O(1) < O(logn) < O(n) < O(nlogn) < O(n\*\*2) < O(n\*\*3) < O(2\*\*n) < O(n!) < O(n\*\*n)


## Liner Table

- 定义: 零个或多个数据元素的有限序列

- 存储方式: 顺序存储, 链式存储

- 顺序存储: 指用一段地址连续的存储单元依次存储线性的数据元素.

- 链式存储: 每个数据结点, 不仅存储数据, 还存储了指向(上)下一个数据结点的指针, 称为(双)单链表. 此外还有静态链表

### Sequence List

- 定义: 它是用一组连续的存储单元依次存储线性表中的数据元素, 从而逻辑上相邻的两个元素在物理上也相邻

- 特点: 随机访问(通过首地址和元素序号可在时间O(1)内找到指定的元素); 存储密度高, 每个结点只存数据元素; 逻辑上相邻的元素物理上也相邻, 插入删除操作需要移动大量元素.

### Linked List

- 定义: 它是指通过一组任意的存储单元来存储线性表中的数据元素. 为了建立数据元素之间的线性关系, 对每个链表结点, 除存放元素自身的信息外, 还需要存放一个指向其后继的指针.

- 特点: 非随机访问

### Stack and Queue

- 栈: 先入后出(FILO)线性表

- 队列: 先入先出(FIFO)线性表

### Matrix

- 数组定义: 线性表的推广(二维数组, 线性表的线性表)

- 二维数组的存储: 先行后列(C语言 array), 或先列后行.


## Tree

- 定义: 树是n(n>=0)个结点的有限集合, n=0时, 称为空树. 对任意一棵非空树应该满足:
    1. 有且仅有一根结点
    2. 当n>1时, 其余结点可分为m(m>=0)个互不相交的有限集合T1, T2, ... , Tm, 其中每一个集合本身又是一棵树

- 特点: 树的根结点没有前驱结点, 除根结点外的所有结点有且仅有一个前驱结点; 树中所有结点可以有零个或多个后继结点.

- 概念:
    1. 父结点, 子结点, 祖先结点, 子孙结点, 兄弟结点
    2. 一个结点的度(一个结点的子结点的个数), 树的度(其中结点最大的度)
    3. 度大于0的结点称为分支结点, 度为0的称为叶子结点
    4. 树的深度(又称高度)
    5. 有序树, 无序树(树中结点的子树从左到右是否有序)
    6. 路径, 路径长度
    7. 森林是m棵不相交的树的集合

- 表示:
    1. 双亲表示法: 用一组连续的空间来存储每个结点, 同时在每个结点中增设一个伪指针, 指示其双亲结点在数组中的位置.  
    特点: 利用了每个结点(除根结点)外, 都只有一个双亲的性质, 可以很快得到每个结点的双新结点, 但求结点的孩子时需要遍历整个结构.  
    2. 孩子表示法: 将每个孩子结点都用单链表链接起来形成一个线性结构, 此时n个结点就有n个孩子链表.  
    特点: 找孩子很容易, 找双亲需要遍历n个结点中的孩子链表.  
    3. 孩子兄弟表示法: 以二叉链表作为树的存储结构,孩子兄弟表示法使每个结点包括三部分内容: 结点值, 指向结点第一个孩子结点的指针, 指向结点下一个兄弟结点的指针  
    特点: 比较灵活, 方便的实现了树转换为二叉树的操作, 易于查找结点的孩子但缺点是查找双亲结点比较麻烦(但可拓展为每个结点存储parent指针)

- 应用:
    1. 并查集  
    定义: 并查集是一种简单的集合表示, 它支持3种操作:  
    - Union(S, Root1, Root2): 把子集合Root2并入子集合Root1中, 要求Root1和Root2互不相交, 否则不执行合并
    - Find(S, x): 查找集合S中单元素x所在的集合, 并返回该集合的名字.
    - Initial(S): 将集合S中的每个元素都初始为只有一个单元素的子集合.
    2. 二叉排序树(二叉查找树)
    定义: 二叉排序是一棵空树或具有如下特性的非空二叉树:
    - 若左子树非空, 则左子树上所有的结点的关键字值均**小于**根结点的关键字值
    - 若右子树非空, 则右子树上所有的结点的关键字值均**大于**根结点的关键字值
    特点: 二叉排序树是一个递归的数据结构; 左<中<右, 所以中序遍历其可得有序序列

### Binary Tree

- 定义: 二叉树是一种树形结构, 其特点是每个结点至多只有两棵子树(即二叉树中不存在度大于2的结点)并且二叉树有左右之分, 其次序不能任意颠倒.

- 几个特殊的二叉树:
    1. 满二叉树: 一棵二叉树所有分支都存在左子树和右子树, 并且所有叶子都在同一层上.(除叶子结点外, 所有分支结点的度为均2; 一棵高度为h的树有 2^h - 1个结点)
    2. 完全二叉树: 设一个高度为h, 有n个结点的二叉树, 当且仅当其每个结点都与高度为h的满二叉树中编号为1~n的结点一一对应时, 称为完全二叉树.
    3. 二叉排序树: 一棵二叉树或是空树, 或者是具有如下性质的二叉树: 左子树上所有结点的关键字均小于根结点的关键字; 右子树上的所有结点的关键字均大于根结点的关键字. 左子树右子树又各是一棵二叉排序树.
    4. 平衡二叉树(AVL): 树上任一结点的左子树与右子树的深度之差不超过1.
    5. 哈夫曼树(最优二叉树): 树的结点的值被称为该结点的权; 从树根结点到任意结点的路径长度(经过的边数)与该结点上权值的乘积, 称为该结点的带权路径长度. 树中所有叶结点的带权路径长度之和称为该树的带权路径长度. 其中带权路径长度(WPL)最小的二叉树称为哈夫曼树, 也称为最优二叉树.

- 二叉树的性质
    1. 非空二叉树的叶子结点数等于度为2的结点数加1, 即 n0 = n2 + 1; (证明, 从结点总数与分支数的关系出发证明)
    2. 非空二叉树上第k层至多有 2^(k-1) 个结点(k从1层起)
    3. 高度为h的二叉树至多有 2^h -1 个结点
    4. 对完全二叉树而言 第i个结点的左孩子(如果有的话)为 2i + 1, 右孩子(如果有的话)为 2i + 2(i从0起)
    5. 对于具有n个结点的完全二叉树, 其高度为log2(n+1)(向上取整), 由上3可得

- 存储方式
    1. 顺序存储: 二叉树的顺序存储是指用一组地址连续的存储单元依次自上至下, 自左至右存储**完全二叉树**上的结点元素(依上性质4)依据一些方法确定结点在逻辑上父子关系. 对一般二叉树, 只能添加一些空结点, 让其成为完全二叉树, 再存储之
    2. 链式存储: 链式存储是指用一个链表来存储一棵二叉树, 二叉树中每个结点用链表的一个链结点来存储. (结点结构包括, 数据域data, 左指针域lchild, 右指针域rchild) (在含有n个结点的二叉链表中, 含有n+1个空链域)

### Thread Tree

- 定义: 遍历二叉树是以一定的规则将二叉树的结点排列成一个线性序列, 从而得到二叉树结点的各种遍历序列, 其实质是对一个非线性结构进行线性化操作, 使这个访问序列中的每个结点(第一个和最后一个结点除外)都有一个直接前驱和后继.

- 特点: n个结点的二叉树, 共有n+1个空指针域; 在二叉树线索化的过程中, 通常规定: 若无左子树, 令lchild指向其前驱结点; 若无右子树, 令rchild指向其后继结点. 还需要增加两个标志域表明当前指针域所指对象是左(右)结点, 还是直接前驱(后继).

- 线索二叉树的构造: 实质是遍历一次二叉树, 只是在遍历的过程中, 检查当前结点左,右指针域是否为空, 若为空, 将它们改为指向当前前驱后继的线索.

### Tree And Forest

- 转化: 孩子兄弟表示法 -> first_child_ptr, first_sibling_ptr

### Balanced Binary Search Tree

示例将要插入的平衡搜索树:

```
    A
  B    AR
BL BR
```

- 定义: 为了避免树的高度增长过快, 降低二叉排序树的性能, 我们规定在插入和删除二叉树结点时, 要保证任意结点的左右子树高度差的绝对值不超过1, 将这样的二叉树称为平衡二叉树, 简称平衡树(AVL). 定义结点左子树与右子树的高度差为该结点的平衡因子, 则平衡二叉树结点的平衡因子的值只可能是-1, 0, 1 定义结点左子树与右子树的高度差为该结点的平衡因子, 则平衡二叉树结点的平衡因子的值只可能是-1, 0, 1.

- 平衡操作: 二叉排序树保证平衡的基本思想如下: 每当在二叉排序树中插入(或删除)一个结点时, 首先检查其插入路径上的结点是否因为此次操作而导致了不平衡. 若导致了不平衡, 则先找到插入路径上离插入结点最近的平衡因子的绝对值大于1的结点A, 再对以A为根的子树, 在保持二叉排序树特性的前提下, 调整各结点的位置关系, 使之重新达到平衡.  
           注意: 每次调整的都是最小不平衡子树
           
- 失衡后的调整:  
    1. LL平衡旋转(右单旋转):  
    由于在结点A的左孩子(L)的左子树(L)上插入了新结点, A的平衡因子由1增至2, 导致以A为根的子树失去平衡, 需要一次向右的旋转操作. 将A的左孩子向右上旋转代替A成为根结点, 而B的原右子树则作为A结点的左子树.
    2. RR平衡旋转(左单旋转):  
    由于在结点A的右孩子(R)的右子树(R)上插入了新结点, A的平衡因子由-1减至-2, 导致以A为根的子树失去平衡, 需要一次向左的旋转操作. 将A的右孩子B向左上旋转代替A成为根结点, 而B的原左子树则作为A结点的右子树.
    3. LR平衡旋转(先左后右双旋转):  
    由于在A的左子树(L)的右子树(R)上插入新结点, A的平衡因子由1增至2, 导致以A为根的子树失去平衡, 需要进行2次旋转操作, 先左旋转后右旋转. 先将A结点的左孩子B的右子树的根结点C向左上旋转提升到B结点的位置, 然后再把该C结点向右上旋转提到A结点的位置.
    4. RL平衡旋转(先右后左双旋转):  
    由于在A的右孩子(R)的左子树(L)上插入新结点, A的平衡因子由-1减至-2, 导致以A为根的子树失去平衡, 需要进行2次旋转操作, 先右旋转再左旋转. 先将A结点的右孩子B的左子树的根结点C向右上旋转提升到B结点的位置, 然后再把该C结点向左上旋转提升到A结点的位置.

### Huffman Tree

- 定义: 带权路径长度(WPL)最小的二叉树称为哈夫曼树(最优二叉树)

- 构造: 给定n个权值分另为w1,w2,...wn的结点, 通过哈夫曼算法可以构造出最优二叉树: 
    1. 将这n个结点分别作为n棵仅含一个结点的二叉树, 构成森林F.  
    2. 构造一个新结点, 从F中选取两棵根结点权值最小的树作为新结点的左,右子树, 并且将新结点的权值置为左,右子树上根结点的权值之和.  
    3. 从F中删除刚选出的两棵树, 同时将新得到的树加入F中.  
    4. 重复步骤2,3 直至只剩下一棵树为止.  

- 性质: 
    1. 每个初始结点最终都成为叶结点, 且权值越小的结点到根结点的路径长度越大.  
    2. 构造过程中一共新建了n-1个结点(双分支结点), 因此哈夫曼树中的结点总数为2n-1.  
    3. 每次构造都选择2棵树作为新结点的孩子, 因此哈夫曼树中不存在度为1的结点.  

- 应用: 
    1. 相关介绍: 固定长度编码 & 可变长度编码 & 前缀编码(没有一个编码是另一个编码的前缀)
    2. 由哈夫曼树得到哈夫曼编码: 首先, 将每个出现的字符当作一个独立的结点, 其权值为它出现的频度(或次数), 构造出对应的哈夫曼树. 显然, 所有字符结点都出现在叶结点中. 我们可将字符的编码解释为从根结点至该字符的路径上标记的序列, 其中边标记为0表示"转向左孩子", 标记为1表示"转向右孩子". (实质, 用最优二叉树对数据进行前缀编码, 压缩了数据长度.)
    
## Graph

- 定义: 图G由顶点集V和边集E组成, 记为G=(V, E), 其中V(G)表示图G中顶点的有限非空集; E(G)表示图G中顶点之间的关系(边)的集合, 则用|V|表示图G中顶点的个数, 也称图G的阶, E={(u,v) | u属于V, v属于V}, 用|E|表示图G中边的条数.

注意: 线性表可以是空表, 树可以是空树, 但图不可以是空图. 就是说, 图中不能一个顶点也没有, 图的顶点集V一定非空, 但边集E可以为空, 此时图中只有顶点而没有边.

- 基本概念:

    1. 有向图: 若E是有向边(也称为弧)的有限集合时, 则图G为有向图. 弧是顶点的有序对, 记为<v, w>, 其中v, 是顶点, v称为弧尾, w称为弧头, <v, w>称为从顶点v到顶点w的弧, 也称v邻接到w, 或w邻接自v.
    2. 无向图: 若E是无向边(简称边)的有限集合时, 则图G为无向图.
    3. 简单图: 一个图G若满足: 1. 不存在重复边; 2. 不存在顶点到自身边, 则称图G为简单图.
    4. 多重图: 若图G中某两个结点之间的边数多于一条, 又允许顶点通过同一条边和自己关联, 则G为多重图. 多重图与简单图是相对的.
    5. 完全图: 也称简单完全图, 在无向图中, 若任意两个顶点之间都存在边, 则称该图为无向完全图, 含有n个顶点的无向完全图有n(n-1)/2条边; 在有向图中, 若任意两个顶点之间都存在方向相反的两条弧, 则称该图为有向完全图. 含有n个结点的有向完全图有n(n-1)条有向边. 
    6. 子图: 设有两个图G=(V, E)和G1=(V1, E1), 若V1是V的子集, 且E1是E的子集, 则称G1是G的子图. 若有满足V(G1) = V(G)的子图G1, 则称其为G的生成子图. 
    7. 连通, 连通图和连通分量: 在无向图中, 若从顶点v到顶点w有路径存在, 则称v和w是连通的. 若图G中任意两个顶点都是连通的, 则称图G为连通图, 否则称为非连通图. 无向图中的极大连通子图称为连通分量.
    8. 强连通图, 强连通分量: 在有向图中, 若从顶点v到顶点w和从顶点w到顶点v之间都有路径, 则称这两个顶点是强连通的. 若图中任何一对顶点都是强连通的, 则称此图为强连通图. 有向图中的极大强连通子图称为有向图的强连通分量.
    9. 生成树, 生成森林: 连通图的生成树是包含图中全部顶点的一个极小连通子图. 若图中顶点数为n, 则它的生成树含有n-1条边. 对生成树而言, 若砍去它的一条边, 则会变成非连通图, 若加上一条边则会形成一个回路. 在非连通图中, 连通分量的生成树构成了非连通图的生成森林. 
    10. 顶点的度, 入度和出度: 图中每个顶点的度定义为以该顶点为一个端点的边的数目. (无向图的顶点的数目是边的2倍, 因为每条边和2个顶点相关联)
    11. 边的权和图: 在一个图中, 每条边都可以标上具有某种含义的数值, 该数值称为该边的权值. 这种边上带有权值的图称为带权图, 也称网.
    12. 稠密图, 稀疏图: 边数很少的图称为稀疏图, 反之称为稠密图. 稀疏与稠密本就是相对概念, 一般而言当图G满足|E|<|Vlog|V||时, 可以将G视为稀疏图
    13. 路径, 路径长度和回路: 顶点Vp到顶点Vq之间的一条路径是指顶点序列VpViVj...Vq. 路径上边的数目称为路径长度. 第一个顶点和最后一个顶点相同的路径称为回路或环. 若一个图有n个顶点, 并且有大于n-1个边, 则一定有环.
    14. 简单路径, 简单回路: 在路径序列中, 顶点不重复出现的路径称为简单路径. 除第一个顶点和最后一个顶点外, 其余顶点不重复出现的回路称为简单回路.
    15. 距离: 从顶点u出发到顶点v的最短路径若存在, 则此路径的长度称为从u到v的距离. 若从u到v根本不存在路径, 则记该距离为∞.
    16. 有向树: 一个顶点的入度为0, 其余顶点的入度均为1的有向图, 称为有向树
    
- 图的存储

图的存储必须完整, 准确地反映顶点集和边集的信息. 根据不同图的结构和算法, 可以采用不同的存储方式, 但不同的存储方式对程序的效率产生相当大的影响. 主要的存储方式有2:  

1). 邻接矩阵法(图的顺序存储): 所谓邻接矩阵存储, 是指用一个一维数组存储图中顶点的信息, 用一个二组数组存储图中边的信息(即各顶点之间的邻接关系), 这样的二组数组称为邻接矩阵.  

特点:  
    1. 无向图的邻接矩阵一定是一个对称矩阵(并且唯一). 因此实际存储邻接矩阵时只需存储上(或下)三角矩阵的元素.  
    2. 对无向图, 邻接矩阵的第i行非零元素的个数正好是第i个顶点的度. 对有向图而言, 为其出(入)度.  
    3. 邻接矩阵存储很容易确定图中任意2个顶点之间是否相连. 但要确定图中有多少条边, 则必须按行列对元素进行检测, 这是登门邻接矩阵存储的局限性.  
    5. 稠密图很适合邻接矩阵的存储表示.

2). 邻接表法(图的链式存储): 所谓邻接表, 是指对图G中的每个顶点vi建立一个单链表, 第i个单链表中的结点表示依附于顶点vi的边, 这个单链表就称为顶点vi的边表(对于有向图为出边表), 边表的头指针(顶点)顺序存储称为顶点表.

特点:  
    1. 若G为无向, 则所需的存储空间为O(|V|+2|E|); 若G为有向图, 则所需的存储空间为O(|V|+|E|).  
    2. 对于稀疏图, 采用邻接表表示能极大的节存储空间.  
    3. 在邻接表中, 给定一顶点, 能很容易地找出它的所有邻边.  
    4. 在有 向图的邻接表表示中, 求一个给定顶点的出度只需计算邻接表中的结点个数; 但求其顶点的入度则需要遍历全部的邻接表.  
    5. 图的邻接表表示并不唯一, 因为在每个顶点对应的单链表中, 各边结点的链接次序可以是任意的, 它取决于建立邻接表的算法及边的图输入次序.  

3). 十字链表(略): 是有向图的一种链式存储结构, 重点在于每个顶点链表记录不是顶点, 而是一条边(弧)的信息, 该弧又记录了弧的(头,尾顶点)及同弧头, 弧尾的下一条弧...

4). 邻接多重表: 是无向图的另一种链式存储结构, 类似于十字链表...

- 图的基本操作

图的基本操作是独立于存储结构的, 对于不同的存储方式, 操作算法的具体实现有不同(性能, 实现上)

1. Adjacent(G, x, y): 判断图G是否存在边E(x, y);
2. Neighbors(G, x): 列出图G中插入顶点x.
3. ...

- 图的遍历

图的遍历是指从图中的某一顶点出发, 按照某种搜索方法沿着图中的边对图中的所有顶点访问一次且仅访问一次. 

1). 广度优先搜索(Breadth-First-Search, BFS)  
广度优先搜索类似于二叉树的层序遍历算法, 其基本思想是: 首先访问起始顶点v, 接着由v出发, 依次访问v的各个未访问过的邻接顶点w1,w2,...,wi, 然后依次w1,w2,...,wi的所有未被访问过的邻接顶点...以此类推, 直到图中所有顶点都被访问过为止. Dijkstra单源最短路径算法和Prim最小生成树算法也应用了类似的思想.  
应用:  BFS算法求解单源最短路径问题; 广度优先生成树;

2). 深度优先搜索(Depth-First-Search, DFS)  
深度优先搜索类似于二叉树的先序遍历. 其基本思想是: 首先访问图中某一起始顶点v, 然后由v出发, 访问与v邻接且未被访问的任一顶点w1, 再访问与w1邻接且未被访问过的任一顶点w2...重复上述过程. 当不能再继续向下访问时, 依次退回到最近被访问的顶点, 若它还有邻接顶点未被访问过, 则从该点开始继续上述搜索过程, 直到图中所有顶点均被访问过为止.  
应用: 深度优先生成树(森林)

- 图的应用

1). 最小生成树(Minimum-Spanning-Tree, MST)

一个连通图的生成树是图的极小连通子图, 它包含图中的所有顶点, 并且只含尽可能少的边. 这意味着对于生成树来说, 若砍去它的一条边, 则会使生成树变成非连通图; 若给它增加一条边, 则会形成图中的一条回路.

对于一个带权连通无向图G=(V, E), 生成树不同, 每棵树的权(即树中所有边上的可能会之和)也可能不同. 其中权值之和最小的那棵生成树T, 称为G最小生成树.

性质:

a. 最小生成树不是唯一的; 当各边权值各不相等时, 最小生成树唯一; 当边数比顶点少少1时(G本身为一棵树), 最小生成树是它自己.

b. 最小生成树的权值之和总是唯一的, 虽然最小生成树不唯一, 但其对应的边的权值之和总是唯一, 且是最小的.

c. 最小生成树的边数为顶点数减1

生成算法:

构造最小生成树的算法有很多, 但大多数算法都利用了最小生成树的下列性质: 假设G=(V,E)是一个带权连通无向图, U是顶点集V的非空子集. 若(u,v)是一条具有小最权值的边, 其中u属于U, v属于V-U, 则必存在一棵包含边(u,v)的最小生成树.

基于该性质的最小生成树的算法主要有Prim算法和Kruskal算法, 它们都基于贪心算法的策略.

```c
// 伪代码描述
GENERIC_MST(G) {
    T=NULL;
    while T未形成一棵生成树;
        do 找到一条最小代码边(u, v)并且加入T后不会产生回路;
            T=T并上(u, v)
}
```

Prim(普里姆)算法:

描述: Prim的算法执行过程非常类似于Dijkstra算法, 假设N={V,E}是连通图, Et是N上最小的生成树中的边的集合, 算法从Vt={u0} (u0属于V), Et={}开始, 重复执行下述操作: 在所有的u属于Vt, v属于V-Vt的边(u, v)属于E中找一条代价最小的边(u0, v0)并入集合Et, 同时将v0并入Vt, 直到Vt=V为止. 此时Et中必有n-1条边, 则T={Vt, Et}为N的最小生成树.

分析: Prim算法的时间复杂度为O(|V|**2), 不依赖于|E|, 因此它适用于求解边稠密的图的最小生成树.

Kruskal(克鲁斯卡尔)算法:

描述: 与Prim算法从顶点开始扩展最小生成树不同, Kruskal(克鲁斯卡尔)算法是一种按权值的递增次序选择合适的边来构造最小生成树的方法. 设N=(V, E)是连通图, 对应的最小生成树T=(Vt, Et), Kruskal算法的步骤如下: 初始化: Vt = V, Et = 空集合. 即每个顶点构成一棵独立的树, T此时是一个仅含|V|个顶点的森林; 循环(重复下列操作至T是一棵树): 按G的边的权值递增顺序依次从E-Et中选择一条边, 若这条边加入T后不构成回路, 则将其加入Et, 否则舍弃, 直到Et中有n-1边条.

```c
// 伪代码描述
void Kruskal(V, T) {
    T=V;
    sumS=n;
    while (numS>1) {
        从E中取出权值最小的边(v, e);
        if (v和u属于不同的连通分量) {
            T=T并{(v,u)};
            sumS--;
        }
    }
}
```

分析: 通常在Kruskal算法中, 采用堆来存入边的集合, 因此每次选择最小权值的边只需要O(log|E|)的时间. 此外, 由于生成树T中的所有边可视为一个等价类, 因此每次添加新的边的过程类似于求解等价类的过程, 由此可以采用并查集的数据结构来描述T, 从而构造T的时间复杂度为O(|E|log|E|). 因此, Kruskal算法适用于边稀疏而顶点较多的图.

2). 最短路径

广度优先搜索查找最短路径只是对无权图而言的. 图是带权图时, 把从一个顶点V0到图中其余任意一个顶点Vi的一条路径(可能不止一条)所经过边上的权值之和, 定义为该路径的带权路径长度, 把带权路径长度最短的那条路径称为最最短路径.

**求解最短路径的算法通常都依赖于一种性质, 即两点之间的最短路径也包含了路径上其他顶点间的最短路径.** 带权有向图的最短路径问题一般可分为两类: 一是单源最短路径, 即求图中某一顶点到其他各顶点的最短路径, 可通过经典的Dijkstra算法求解; 二是求每对顶点间的最短路径, 可通过Floyd-Warshall算法求解.

Dijkstra算法求单源最小路径问题

重要数据结构:

arcs[][]: 图的邻接矩阵表示两点间的边的权值(距离)  
dist[]: 记录从源点V0到其他各顶点当前的最短路径长度, `dist[i]` 的初值为`arcs[V0][i]`. (注意, 此初始值为直接可达距离).  
path[]: `path[i]` 表示从源点到顶点i之间的最短路径的前驱结点, 在算法结束时, 可根据其值追溯到源点V0到顶点Vi的最短路径.  

描述: 算法步骤如下(不考虑对path[]的操作):  

a. 初始化: 集合S初始化为{V0}, `dist[i]=arcs[0][i], i=1,2,3,...,n-1`;  

b. 从顶点集合V-S中选出Vj, 满足`dist[j]=Min(dist[i], Vi属于V-S)`, Vj就是当前求得的一条从V0出发的最短路径的终点, 令S=S并{j};  

c. 修改从V0出发的到V-S上任一顶点Vk的可达的最短路径长度: 若`dist[j]+arcs[j][k]<dist[k]` 则`dist[k]=dist[j]+arcs[j][k]<dist[k]`;(实质是新的顶点加入, 对原先"最短路径"的影响)

d. 重复2-3, 操作共n-1次, 直到所有顶点都包含在S中.

思考Dijkstra算法与Prim算法的相似之处: Dijkstra算法每一步得到的路径dist[]都是当前顶点集合中的最优路径. Prim算法(求解最小生成树)直接每一步取的就是当前顶点中最优边的集合...(个人理解)
    
分析: 显然Dijkstra算法也基于贪心策略. 时间复杂度为O(|V|^2).

Floyd算法求各顶点之间最短路径问题

求所有顶点之间的最短路径问题描述如下: 已知一个各边权值均大于0的带权有向图, 对每对顶点Vi!=Vj, 要求求出Vi与Vj之间的最短路径和最短路径长度.

描述: Floyd算法基本思想是:  

递推产生一个n阶方阵序列A(-1), A(0), A(1),...,A(n-1)其中`A(k)[i][j]`表示从顶点Vi到Vj的路径长度, k表示**绕行(中转)**第k个顶点运算步骤.   

a. 初始时, 对于任意两个顶点Vi和Vj, 若它们之间存在边, 则以此边上值作为它们之间的最短路径长度; 若它们之间不存在有向边, 则以无穷作为它们之间的最短路径长度.  

b. 以后逐步尝试在原路径中加入顶点k(k=0,1,...,n-1)作为中间顶点. 若增加蹭顶点后, 得到的路径比原来的路径长度减少了, 则以此新路径代替原路径.
    
`A(k)[i][j]`是从顶点Vi到Vj, 中间顶点的序号不大于k的最短路径长度. Floyd算法是一个迭代的过程, 每迭代一次, 在从Vi到Vj的最短路径上就多考虑了一个顶点; 经过n次迭代后, `A(n-1)[i][j]`就是Vi到Vj的最短路径长度, 即方阵A(n-1)就保存了任意一对顶点之间的最短路径长度.

分析: 时间复杂度|V|^3

3). 拓扑排序

有向无环图: 若一个有向图中不存在环, 则称为有向无环图, 简称DAG图.

AOV图: 若用DAG(有向无环图)图表示一个工程, 其顶点表示活动, 用有向边`<Vi, Vj>`表示活动Vi必须先于活动Vj进行的这样一种关系, 则将这种有向图称为**顶点表示活动的网络**, 记为AOV网.

拓扑排序: 在图论中, 由一个有向无环图的顶点组成的序列, 当且仅当满足下列条件时, 称为该图的一个拓扑排序:  

a. 每个顶点出现且只出现一次.  

b. 若顶点A在序列中排在顶点B前面, 则在图中不存在从顶点B到顶点A的路径.  

c. 或者定义为: 拓扑排序是对有向无环图的顶点的一种排序, 它使得若存在一条从顶点A到顶点B的路径, 则在排序中顶点B出现在顶点A的后面. 每个DAG图(有向无环图)都有一个或多个拓扑排序序列. 

常用方法:  

a. 从DAG图中选择一个没有前驱的顶点并输出.

b. 从图中删除该顶点和所有以它为起点的有向边.

c. 重复a,b操作直到当前的DAG图为空或当前图中不存在无前驱的顶点为止. 后一种情况说明有向图中必然存在环(不为DAG图).

4). 关键路径

描述: 在带权有向图中, 以顶点表示事件, 以有向边表示活动, 以边上的权值表示完成该活动的开销(如完成活动所需的时间), 则称这种有向图为用边表示活动的网络图, 简称AOE网.

AOE网具有2个性质:

a. 只有在某顶点所代表的事件发生后, 从该顶点出发的各有向边所代表的活动才能开始;

b. 只有在进入某一顶点的各有向边所代表的活动都已结束时, 该顶点所代表的事件才能发生.

在AOE网中有且仅有一个入度为0的顶点, 称为开始顶点(源点), 它表示整个工程的开始; 网中也仅存在一个出度为0的顶点, 称为结束顶点(汇点), 它表示整个工程的结束.

有AOE网中, 有些活动是可以并行的, 从源点到汇点可能有多条路径, 并且这些路径的长度也可能不同. 只有当所有路径上的活动都已经完成, 整个工程才能算结束. 因此把具有最大路径长度的路径称为关键路径, 而把关键路径上的活动称为关键活动.

## Find

查找: 在数据集合中寻找满足条件的数据元素的过程称为查找. 

查找表(查找结构): 用于查找的数据集合称为查找表, 分为静态查找表, 动态查找表.

关键字: 数据元素中唯一标识该元素的某个数据项的值.

平均查找长度: 在一次查找过程中需要比较关键词的次数, 而平均查找长度则是所有查找过程中进行关键词的平均值.

- 顺序查找与折半查找

顺序查找

又称线性查找, 主要用于在线性表中进行查找, 又分为一般线性表的顺序查找和有序表的顺序查找(它们区别在于平均失败查找长度略有不同...)

折半查找

又称二分查找, 它仅适用于有序表. 

分块查找

又称索引顺序查找, 它吸取了顺序查找和折半查找各自的优点, 既有动态结构, 又适于快速查找.

分块查找的基本思想: 将查找表分为若干子块. 块内的元素可以无序, 但块之间是有序的.

- B树和B+树

B树, 又称多路平衡查找树, B树中所有结点的孩子结点数的最大值称为B树的阶, 通常用m表示. 一棵m阶B树或为空树, 或为满足如下我的m叉树:

1. 树中每个结点至多有m棵子树(即至多含有m-1个关键字)
2. 若根结点不是终端结点, 则至少有两子树.
3. 除根结点外的所有非叶结点至少有m/2(向上取整)棵子树(即至少有m/2(向上取整)-1个关键字)
4. 所有非叶结点的结构如下: `n, P0, K1, P1, K2, P2, ... , Kn, Pn`. 其中Ki为结点的关键字, 且满足K1<K2<K3< ... <Kn; Pi(i=0,1,...,n)为指向子树根结点的指针, 且指针Pi-1所指子树中所有结点的关键字均小于Ki, Pi所指子树中所有结点的关键字均大于Ki, n(m/2(向上取不整)-1<n<m-1)为结点中关键字的个数
5. 所有叶结点都出于同在同一层次上, 并且不带信息(可以视为外部结点或类似于折半查找判定树的查找失败结点, 实际上这些结点不存在, 指向这些结点的指针为空)

B树是所有结点的平衡因子均等于0的多路查找树.

B树的高度(磁盘存取次数)

B树的查找: 在B树上进行查找与二叉查找树很相似, 只是每个结点都是多个关键字的有序表, 在每个结点上所做的不是两路分支决定, 而是根据该结点的子树所做的多路分支决定. B树的查找包含两个基本操作: 1. 在B树中找到结点; 2. 在结点内找到关键字. 由于B树常存储在磁盘上, 因此前一个查找操作是在磁盘上进行的, 而后一个查找操作是在内在中进行的, 即在找到目标后, 先将结点中的信息读入内存, 然后采用顺序查找法或折半查找法查找等于K的关键字.

B树的插入: 与二叉查找树的操作相比, B树的插入操作要复杂的多. 在B树中插入元素, 要进行调整, 使之插入后仍满足B树的定义. 主要分为2步: 1. 定位, 利用前述的B树查找算法, 找出敀该关键词的最低层中的某个非叶结点(注意, B树中的插入关键字一定插入在最低层中的某个非叶结点内). 2. 插入, 在B树中, 每个非失败结点的关键定个数都在区间`[m/2 -1, m-1]`. 插入后的结点关键字个数小于m, 可以直接插入; 插入后检查被插入关键字的个数, 当插入后的结点关键字个数大于m-1时, 必须对结点进行分裂. 

分裂的方法是: 取一个新结点, 在敀key后的原结点, 从蹭位置将其中的关键字分为两部分, 左部分包含的关键字放在原结点中, 右部分包含的关键字放到新结点中, 蹭位置m/2(向上取整)的结点插入原结点的父结点. 若些时导致其父结点的关键字个数也超过了上限, 则继续进行这种分裂操作, 直到这个过程传到根结点为止, 进而导致B树高度增1.

B树的删除: :) 分为1. 删除关键字不是终端结点(最低层非叶结点): 2. 删除关键字在终端结点(可直接删; 兄弟够借; 兄弟不够借...)

B+树的基本概念:

B+树是应数据库所需而出现的一种B树的变形树. 一棵m阶的B+树需满足下列条件: 

1. 每个分支结点最多有m棵子树(结点).
2. 非叶根结点至少有两棵子树, 其他每个分支结点至少有m/2(向上取整)棵子树.
3. 结点的子树个数与关键字个数相等.
4. 所有叶结点包含全部关键字及指向相应记录的指针, 叶结点中将关键字按大小顺序排列, 并且相邻叶结点按大小顺序相互链接起来.
5. 所有分支结点(可视为索引的索引)中仅包含它的各个子结点(即下一级的索引块)中关键字的最大值及指向其子结点的指针.

m阶的B+树与B树的主要差异如下:

1. 在B+树中, 具有n个关键字的结点只含有n棵子树, 即每个关键字对应一棵子树; 而在B树中, 具有n个关键字的结点含有n+1个子树.
2. 在B+树中, 每个结点(非根结点)的关键字的个数n的范围是m/2(向上取整)<=n<=m(根结点1<=n<=m); 而在B树中, 关键字(非根结点)的关键字的个数n的范围是m/2(向上取整)-1<=n<=m-1(根是1<=n<=m=1).
3. 在B+树中, 叶结点包含信息, 所有非叶结点仅起索引作用, **非叶结点中的每个索引项**只含有对应子树的最大关键字和指向该子树的指针, 不含有该关键字对应记录的存储地址.
4. 在B+树中, 叶结点包含了全部的关键字, 即在非结点中出现的关键字也会出现在叶结点中; 而在B树中, 叶结点包含的关键字和其他结包含的关键字是不重复的.

通常B+树中有两个头指针:  一个指向根结点; 另一个指向关键字最小的叶结点. 因此, 可以对B+树进行两种查找运算: 一种是从最小关键字开始的顺序查找; 另一种是从根结点开始的多路查找.

- 散列表

散列函数: 一个把查找表中的关键字映射成该关键字对应的地址的函数, 记为Hash(key)=Addr(这里的地址可以是数组下标, 索引或内在地址等). 散列函数可能会把两个或两个以上的不同的关键字映射到同一地址, 称之为冲突.

散列表 : 根据关键字而直接访问的数据结构(散列表建立了关键字和存储地址之间的一种映射关系). 理想情况下, 对散列进行查找的时间复杂度为O(1)(无冲突)

散列函数的构造方法:

构造散列函数的注意点: 

1. 散列函数的定义域必须包含全部需要存储的关键字, 而值域的范围则依赖于散列表的大小或地址范围.
2. 散列函数计算出来的地址应该能等概率, 均匀地分布在整个地址空间中, 从而减少冲突的发生.
3. 散列函数应尽量简单, 能够在较短的时间内计算出任一关键字对应的散列地址.

常用的散列函数:

1. 直接定址法: H(key)=a*key+b, 适用于关键字分布基本连续的情况.
2. 除留余数法: H(key)=key%p(p为不大于表长m, 但最接近或等于m的质数p), 关键选好p, 使得冲突较少.
3. 数字分析法: 设关键字是r进制数(如十进制数), 而r个数码在各位上出现的频率不一定相同, 可能在某些位上分布均匀些, 每种数码出现的机会均等; 而在某些位上分布不均匀, 只有某几种数码经常出现, 此时应选取数码分布较为均匀的若干位作为散列地址, 适用于某一类关键字.
4. 平方取中法: 取关键字的平方值的中间几位作为散列地址, 具体取多少位要视实际情况而定. 适用于关键字的每位取值都不够均匀或均小于散列地址所需的位数.
5. 折叠法: 将关键字分割成倍数相同的几部分(最后一部分的位数可以短一些), 然后取这几部分的叠加和作为散列地址. 适用于关键字位数很多, 而且关键字中的每位上数字分布大致均匀.

处理冲突的方法:

1. 开放定址法: 是指可存放新表顶的空闲地址既向它的同义词表项开放, 又向它的非同义词表项开放. 其数学递推公式为 Hi=(H(key)+di)%m
2. 拉链法(链接法, chaining): 把所有同义词存储在一个线性链表中, 这个线性链表由其散列地址唯一标识. 拉链法适用于经常进行插入和删除的情况.

散列查找及性能分析: 散列表的查找效率取决于三个因素: 散列函数, 处理冲突的方法和装填因子(表中记录数n/散列表长度m)

- 串

存储方式:

1. 定长顺序存储表示
2. 推分配存储表示
3. 块链存储表示

串的模式匹配

子串的定位操作通常称为串的模式匹配, 它求的是子串(常称为模式串)在主串中的位置.

KMP算法: 利用比较过的信息, i指针不需要回溯, 仅将子串向后滑动一个合适的位置, 并从这个位置开始和主串进行比较, 这个合适的位置仅与子串本身的结构有关, 而与主串无关.

前缀, 后缀和部分匹配

前缀: 指除最后一个字符以外, 字符串的所有头部子串; 后缀: 指除第一个字符外, 字符串的所有尾部子串; 部分匹配值则为字符串的前缀和后缀的最长相等前后缀长度

部分匹配值: 字符串的前缀和后缀的最长相等长度.

KMP算法的原理: 实质是利用主串与模式串的存在较多重复(部分匹配值), 主串不回溯. 关键在于求解Next函数

例如: 对于模式串abcxyzabcd当最后一个d与主串产生失配时, d前的abc必然是与主串相匹配的, 此时, 主串不回溯至此次比较的开始, 重新从模式串的开头再比较, 因为知道模式串开头abc与结尾部分的abcd中的abc是相同的, 则当d失配时, 只需要将模式串移动至前一个abc后面的x处, 继续与主串比较即可...

```c
void get_next(String T, int next[]) {
    int i=1, j=0;
    // 数组1起
    next[1]=0;
    while (i<T.length) {
        if (j==0||T.ch[i]==T.ch[j]) {
            // 对应该位置的模式串的延伸...
            ++I, ++j;
            next[j]=j;
        } else {
            // 作为另一个`失配问题`, 继续寻找其next...
            j=next[j]
        }
    }
}
```

此时KMP算法如下:

```c
int index_kmp(String S, String T, int next[], int pos) {
    int i=pos, j=1;
    while (i<=S.length&&j<=T.length) {
        if (j==0||S.ch[i]==T.ch[j]) {
            // 继续比较后续的字符
            ++i, ++j;
        } else {
            // 移动模式串
            j=next[j];
        }
    }
    if (j>T.length) {
        // 匹配成功
        return i-T.length;
    } else {
        return 0;
    }
}
```